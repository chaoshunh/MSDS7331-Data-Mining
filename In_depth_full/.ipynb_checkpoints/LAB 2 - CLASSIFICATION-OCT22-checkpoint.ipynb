{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>DALLAS CRIME DATA</center></h1>\n",
    "<h2><center>MSDS 7331 LAB 2</center></h2>\n",
    "<h2><center>Classification Modelling</center></h2>\n",
    "\n",
    "<h4><center>Team Members</center></h4>\n",
    "\n",
    "           Yejur Singh Kunwar           Bin Yu               Vivek Viswanathan          Kevin Mendonsa\n",
    "              Dallas, TX               Dallas, TX               Dallas, TX                Irvine, CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "##### Data Description\n",
    "The Dallas Crime Incident data set used in Lab 2 acts as a bridge between the citizens of Dallas and the Dallas PD. It represents the Dallas Police Public Data - RMS Incidents from June 1, 2014 to September 7, 2018. \n",
    "For purposes of this Lab2, the main dataframe has been trimmed based on the analysis performed for Lab 1. The details of the data quality clean up and choice of columns have been detailed in the Lab 1 notebook link below.\n",
    "\n",
    "The data set currently has 222,147 rows and 45 columns.\n",
    "\n",
    "**Lab 1 Notebook Link -** https://github.com/wtubin/MSDS7331-Data-Mining/MSDS7331_Data_Mining_Lab1_Data-Viz_Pre-Processing.ipynb\n",
    "**Note -** The structure of the document will closely follow the phases of the CRISP-DM Modeling Phase.\n",
    "\n",
    "##### Objective\n",
    "\n",
    "The objective of this unit is to perform Predictive Analysis (Classification) on the chosen data set and apply new classification algorithms. The first task of this lab is to clasify the arrest made in the incident call based on the selected features in the dataset. The second task will attempt to categorize the response time (speed of dispatch) into the categories that have been defined below.\n",
    "\n",
    "**GitHub Repository containing the artifacts -** https://github.com/wtubin/MSDS7331-Data-Mining\n",
    "\n",
    "**Location of the raw (compressed) data file -** https://github.com/wtubin/MSDS7331-Data-Mining/Police_Incidents.7z \n",
    "\n",
    "As part of this analysis, we are attempting to train and test our classification models Stratified Shuffle Split technique. The details of the Stratified Shuffle Split are discussed in the subsequent sections.\n",
    "\n",
    "**The EvaluateClassifierEstimator function from Dr. Drew's NC Education project GitHub has been modified so as to output Accuracy, Precision, and Recall. We'll use these parameters to evaluate the effectiveness of our model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Assumptions\n",
    "For purposes of our modeling, we have performed the following transformations to ensure:\n",
    " * All features are uniformly distributed with 0 mean and unit standard deviation\n",
    " * Features are scaled to ensure that one of the features does not have more emphasis than another\n",
    " * Multi-colinearity has been removed\n",
    " * Features have been converted to categories to improve model efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "The dataset is loaded into the workspace as a data frame and undergoes transformation or standardization before being fed into model. The attributes with zero variance (closer) or those attributes that does not have value in predicting the respose variable are removed. For example attributes like beats, sector, Location1, etc. serves no purpose for our model. \n",
    "\n",
    "Once the unwanted attributes are removed, we're left with attributes that can contribute to our model. Since these attributes will help us classify the Response, going forward, we will refer to the Explanatory variables as Features.\n",
    "\n",
    "Then dataset is split into explanatory, for running the models.\n",
    "\n",
    "        - TASK 1\n",
    "            - inci_X : Explanatory variables (Features)\n",
    "            - inci_Y : Response variable (Arrest_status)\n",
    "        \n",
    "        - TASK 2\n",
    "            - inci_res_X : Explanatory variables (Features)\n",
    "            - inci_res_Y : Response variable (Response_time_cat)\n",
    "        \n",
    "\n",
    "\n",
    "The Features are being scaled to have a mean of 0 and variance of 1 in order to imporve accuracy of the classification models. The data will be split into 80/20 training/test set. We have tested the models with different paramters in order to choose the best parameters for our data set. e.g. Model was fitted with different values of K in the KNN algorithm; different values of metric was used to identify the best fit for our data set.\n",
    "\n",
    "Correlation scores, variance inflaion scores, variance inflation factors (VIFs) and significance has been utilized for manual determination of Features. This will help with feature reduction or feature selection for our final model. The remaining features will be utilized in our models: KNN, Nearest Centroid and Support Vector Machine (SVM). We used a simple for loop to test out different parameters for our models.\n",
    "\n",
    "The following techniques have been used during the analysis to improve the performance and accuracy.\n",
    " - Class balancing using down sampling\n",
    " - Removing Multicolinearity by reviewing correlation matrix\n",
    " - Removing Multicolinearity by reviewing VIF\n",
    " - Scaling the features\n",
    " - Stratified Shuffle Split\n",
    " \n",
    "A brief description of the purpose and outcome of each of the techniques is explained as they are being applied to the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages for python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.tools as tls\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data from Lab#1 and exploring the data, the csv file is the result dataset from Lab1\n",
    "path = \"../../Data/\" # Generic path\n",
    "incident = pd.read_csv(path + 'LAB1_completed_Dataset_clean.csv', low_memory= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223803, 46)\n",
      "Number of null columns and their counts\n",
      "Type_Location                3828\n",
      "Reporting_Area                129\n",
      "Beat                           53\n",
      "Sector                         53\n",
      "Call_Cleared_Date_Time        148\n",
      "Call_Dispatch_Date_Time        21\n",
      "Offense_Status                399\n",
      "Victim_Condition           206053\n",
      "Family_Offense                 29\n",
      "Weapon_Used                 23889\n",
      "UCR_Offense_Name            12102\n",
      "UCR_Code                    12102\n",
      "X_Coordinate                17588\n",
      "Y_Coordinate                17588\n",
      "State                         536\n",
      "Call_Cleared                  148\n",
      "Call_Dispatch                  21\n",
      "Latitude                     8362\n",
      "Longitude                    8362\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exploring the dataset\n",
    "incident['Response_time'] = incident['Response_time'].fillna(incident['Response_time'].mean()).astype(np.int)\n",
    "# 0-11 (Emergency), 11-31(Urgent), 31-60(Important), (60-max)(Non_Urgent)\n",
    "incident['Res_time_category'] = pd.cut(incident.Response_time,[0,11,31,60,1e6],2,labels=[0,1,2,3])\n",
    "incident = incident[incident['Res_time_category'].isnull()==False]\n",
    "\n",
    "incident = incident[incident['Call_Received_Hour'].isnull()==False]\n",
    "incident_NullCols = incident.isnull().sum()\n",
    "incident_NullCols = incident_NullCols[incident_NullCols > 0]\n",
    "\n",
    "# Print out the data properties\n",
    "print(incident.shape)\n",
    "print('Number of null columns and their counts')\n",
    "print(incident_NullCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further cleanup the dataset\n",
    "incident = incident[incident['Watch']!=0]\n",
    "incident = incident[(incident['Victim_Age']>=0) & (incident['Victim_Age']<=90)]\n",
    "incident = incident[incident['Victim_Race']!=\"Unknown\"]\n",
    "incident = incident[incident['Victim_Type']!=\"Unknown\"]\n",
    "incident= incident[incident.Number_of_offense != \"RP\"]\n",
    "\n",
    "incident = incident[incident['Victim_Gender']!=\"U\"]\n",
    "\n",
    "# Further data clean up of feature variables\n",
    "incident.loc[:,'UCR_Offense_Name'] = incident['UCR_Offense_Name'].fillna(\"MISSING\")\n",
    "\n",
    "# Setup the UCR Offense Name Groups\n",
    "THEFT_FRAUD     = dict.fromkeys(['THEFT/BMV', 'THEFT ORG RETAIL', 'BURGLARY-RESIDENCE', 'OTHER THEFTS',\n",
    "                                 'ROBBERY-INDIVIDUAL','THEFT/SHOPLIFT', 'BURGLARY-BUSINESS', 'FORGE & COUNTERFEIT', \n",
    "                                 'FRAUD', 'EMBEZZLEMENT','ROBBERY-BUSINESS','THEFT ORG RETAIL'],\"THEFT_FRAUD\" ) \n",
    "MVA_TRAFFIC      =dict.fromkeys(['ACCIDENT MV', 'MOTOR VEHICLE ACCIDENT', 'UUMV', 'TRAFFIC VIOLATION',\n",
    "                                 'TRAFFIC FATALITY'],\"MVA_TRAFFIC\" )        \n",
    "WEAPONS_FIREARMS =dict.fromkeys(['WEAPONS', 'ARSON', 'INJURED FIREARM'], \"WEAPONS_FIREARMS\")         \n",
    "ASSUALT          = dict.fromkeys(['ASSAULT','VANDALISM & CRIM MISCHIEF', 'AGG ASSAULT - NFV', 'OFFENSE AGAINST CHILD',\n",
    "                                  'AGG ASSAULT - FV'], \"ASSUALT\")\n",
    "OTHERS_THREATS   = dict.fromkeys(['FOUND', 'OTHERS', 'LOST', 'CRIMINAL TRESPASS', 'DISORDERLY CONDUCT', \n",
    "                                  'ANIMAL BITE','INJURED HOME','INJURED PUBLIC', 'TERRORISTIC THREAT', \n",
    "                                  'EVADING', 'INJURED OCCUPA', 'ORANIZED CRIME', 'KIDNAPPING', \n",
    "                                  'RESIST ARREST','FAIL TO ID', 'HUMAN TRAFFICKING', 'MISSING'], \"OTHERS_THREATS\")\n",
    "INTOXICATION     = dict.fromkeys(['DRUNK & DISORDERLY', 'DWI', 'NARCOTICS & DRUGS', 'LIQUOR OFFENSE', \n",
    "                                  'INTOXICATION MANSLAUGHTER'],\"INTOXICATION\")\n",
    "MURDER_DEATH     = dict.fromkeys(['SUDDEN DEATH&FOUND BODIES','MURDER'], \"MURDER_DEATH\")\n",
    "                    \n",
    "# Regroup the UCR_Offense_Name\n",
    "incident.loc[:,'UCR_Offense_Name']= incident['UCR_Offense_Name'].replace(THEFT_FRAUD)\n",
    "incident.loc[:,'UCR_Offense_Name']= incident['UCR_Offense_Name'].replace(MVA_TRAFFIC)\n",
    "incident.loc[:,'UCR_Offense_Name']= incident['UCR_Offense_Name'].replace(WEAPONS_FIREARMS)\n",
    "incident.loc[:,'UCR_Offense_Name']= incident['UCR_Offense_Name'].replace(ASSUALT)\n",
    "incident.loc[:,'UCR_Offense_Name']= incident['UCR_Offense_Name'].replace(OTHERS_THREATS)\n",
    "incident.loc[:,'UCR_Offense_Name']= incident['UCR_Offense_Name'].replace(INTOXICATION)\n",
    "incident.loc[:,'UCR_Offense_Name']= incident['UCR_Offense_Name'].replace(MURDER_DEATH)\n",
    "\n",
    "# Change nominal attributes to numeric\n",
    "incident.loc[:,'IsMale'] = incident.Victim_Gender=='M' \n",
    "incident.IsMale = incident.IsMale.astype(np.int)\n",
    "incident.loc[:,'Social_crime_score'] = incident['Hate_Crime']+incident['Gang_Related_Offense']+incident['Drug_Related']\n",
    "incident.loc[:,'Victim_Age'] = incident['Victim_Age'].astype(np.int)\n",
    "incident.loc[:,'Number_of_offense']= incident.Number_of_offense.astype(np.int)\n",
    "\n",
    "# Coding\n",
    "incident['UCR_Offense_Name'] = pd.Categorical(incident['UCR_Offense_Name']).codes\n",
    "incident['Day1_of_the_Week'] = pd.Categorical(incident['Day1_of_the_Week']).codes\n",
    "incident['Division'] = pd.Categorical(incident['Division']).codes\n",
    "incident['Victim_Type'] = pd.Categorical(incident['Victim_Type']).codes\n",
    "incident['Victim_Race'] = pd.Categorical(incident['Victim_Race']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unixtime(time):    \n",
    "    return (time.astype(np.int64)/1e6).astype(np.int64)\n",
    "\n",
    "import time\n",
    "incident['Call_Received_Date_Time'] = pd.to_datetime(incident['Call_Received_Date_Time'])\n",
    "incident['Call_Cleared_Date_Time'] = pd.to_datetime(incident['Call_Cleared_Date_Time'])\n",
    "incident['Call_Dispatch_Date_Time'] = pd.to_datetime(incident['Call_Dispatch_Date_Time'])\n",
    "\n",
    "incident['Call_Received_Date_Time_epoch']= get_unixtime(incident['Call_Received_Date_Time'])\n",
    "incident['Call_Cleared_Date_Time_epoch']=get_unixtime(incident['Call_Cleared_Date_Time'])\n",
    "incident['Call_Dispatch_Date_Time_epoch']=get_unixtime(incident['Call_Dispatch_Date_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that do not contribute towards our model\n",
    "incident = incident.drop(['Year_of_Incident', 'Service_Number_ID', 'Type_of_Incident','Type_Location', \n",
    "                          'Reporting_Area', 'Beat', 'Sector','Council_District','Call_Received_Date_Time',\n",
    "                          'Call_Cleared_Date_Time', 'Call_Dispatch_Date_Time','Person_Involvement_Type', \n",
    "                          'Victim_Gender', 'Offense_Status', 'Victim_Condition','Family_Offense', 'Weapon_Used', \n",
    "                          'RMS_Code', 'UCR_Code', 'Zip_Code', 'City', 'State',\n",
    "                          'Location1', 'Call_Received', 'Call_Cleared', 'Call_Dispatch','Latitude', 'Longitude'],axis=1)\n",
    "\n",
    "incident= incident.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 184971 entries, 0 to 255153\n",
      "Data columns (total 20 columns):\n",
      "Unnamed: 0              184971 non-null int64\n",
      "Watch                   184971 non-null int64\n",
      "Division                184971 non-null int8\n",
      "Day1_of_the_Week        184971 non-null int8\n",
      "Victim_Type             184971 non-null int8\n",
      "Victim_Race             184971 non-null int8\n",
      "Victim_Age              184971 non-null int32\n",
      "Hate_Crime              184971 non-null int64\n",
      "Gang_Related_Offense    184971 non-null int64\n",
      "Drug_Related            184971 non-null int64\n",
      "UCR_Offense_Name        184971 non-null int8\n",
      "X_Coordinate            184971 non-null float64\n",
      "Y_Coordinate            184971 non-null float64\n",
      "Number_of_offense       184971 non-null int32\n",
      "Response_time           184971 non-null int32\n",
      "Arrest_status           184971 non-null int64\n",
      "Call_Received_Hour      184971 non-null float64\n",
      "Res_time_category       184971 non-null category\n",
      "IsMale                  184971 non-null int32\n",
      "Social_crime_score      184971 non-null int64\n",
      "dtypes: category(1), float64(3), int32(4), int64(7), int8(5)\n",
      "memory usage: 19.4 MB\n"
     ]
    }
   ],
   "source": [
    "incident.info()\n",
    "\n",
    "## TRY ADDING UCR_OFFENSE_DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incident= incident[['Watch', 'Division', 'Day1_of_the_Week', 'Victim_Type', 'Victim_Race',\n",
    "#                     'Victim_Age', 'Hate_Crime', 'Gang_Related_Offense', 'Drug_Related',\n",
    "#                     'UCR_Offense_Name', 'Number_of_offense',\n",
    "#                     'Response_time', 'Arrest_status', 'Call_Received_Hour', 'IsMale',\n",
    "#                     'Social_crime_score', 'Call_Received_Date_Time_epoch',\n",
    "#                     'Call_Cleared_Date_Time_epoch', 'Call_Dispatch_Date_Time_epoch']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Variable Analysis\n",
    "\n",
    "As part of this analysis, we look at the distinct values and distribution of the response variable. \n",
    "\n",
    "- Arrest status\n",
    "\n",
    "- Response time category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 166451\n",
      "Class 1: 18520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore response variable distribution\n",
    "plt.figure(figsize=(8,5))\n",
    "target_count = incident.Arrest_status.value_counts()\n",
    "print('Class 0:', target_count[0])\n",
    "print('Class 1:', target_count[1])\n",
    "# print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
    "\n",
    "# Draw bar plot\n",
    "\n",
    "# data to plot\n",
    "n_groups = 1\n",
    "NoArrest=incident.Arrest_status.value_counts()[0]\n",
    "Arrest=incident.Arrest_status.value_counts()[1]\n",
    " \n",
    "# create plot\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.5\n",
    "opacity = 0.8\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(index, NoArrest, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='g',\n",
    "                 label='No Arrest')\n",
    " \n",
    "plt.bar(index + bar_width, Arrest, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 label='Arrest')\n",
    " \n",
    "plt.xlabel('Arrest Status')\n",
    "plt.ylabel('Number of Incident')\n",
    "plt.title('Dallas City Police Incident Vs. Arrest Status Before Resampling')\n",
    "plt.xlim(-0.8, 2)\n",
    "plt.xticks(index + bar_width/2, (''))\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 94192\n",
      "Class 1: 44893\n",
      "Class 2: 27847\n",
      "Class 3: 18039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore response variable distribution\n",
    "plt.figure(figsize=(8,5))\n",
    "target_count = incident.Res_time_category.value_counts()\n",
    "print('Class 0:', target_count[0])\n",
    "print('Class 1:', target_count[1])\n",
    "print('Class 2:', target_count[2])\n",
    "print('Class 3:', target_count[3])\n",
    "\n",
    "# print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
    "# print('Proportion1:', round(target_count[0] / target_count[2], 2), ': 1')\n",
    "# print('Proportion2:', round(target_count[0] / target_count[3], 2), ': 1')\n",
    "\n",
    "# (0-11)(Emergency), 11-31(Urgent), 31-60(Important), (60-max)(Non_Urgent)\n",
    "\n",
    "\n",
    "# data to plot\n",
    "n_groups = 1\n",
    "Emergent=incident.Res_time_category.value_counts()[0]\n",
    "Urgent=incident.Res_time_category.value_counts()[1]\n",
    "Important=incident.Res_time_category.value_counts()[2]\n",
    "Non_Urgent=incident.Res_time_category.value_counts()[3] \n",
    "# create plot\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.5\n",
    "opacity = 0.8\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(index, Emergent, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='g',\n",
    "                 label='Emergency')\n",
    " \n",
    "plt.bar(index + bar_width, Urgent, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 label='Urgent')\n",
    " \n",
    "plt.bar(index + bar_width+ 0.5, Important, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 label='Important')\n",
    "\n",
    "plt.bar(index + bar_width+ 1.0 , Non_Urgent, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='c',\n",
    "                 label='Non_Urgent')\n",
    "\n",
    "plt.xlabel('Response time category')\n",
    "plt.ylabel('Number of Incident')\n",
    "plt.title('Dallas City Police Incident Vs. Response time Before Resampling')\n",
    "plt.xlim(-0.8, 2)\n",
    "plt.xticks(index + bar_width/2, (''))\n",
    "plt.legend()\n",
    " \n",
    "plt.show()\n",
    "incident_response_time_cat = incident.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling (Downsampling) the data set\n",
    "\n",
    "Based on the above analysis, we have almost 10 times the number of samples for perpetrator not being arrested compared to where an arrest is made. \n",
    "\n",
    "In an imbalanced class, we cannot reliably use accuracy to measure performance. This makes training the model very tricky. The model may predict the majority class better and sometimes ignore the minority class completely. There are 2 ways to blanace the data set: downsampling and upsampling. We selected the downsampling as we have a big dataset. It will run long time in SVM if we choose upsampling method.\n",
    "\n",
    "We perform down-sample by \n",
    "1. Separating observations based on class\n",
    "2. Resample the majority class without replacement after setting the number of samples to match the minorit class count\n",
    "3. Combine the down-sampled majority class and the original minority class\n",
    "\n",
    "Finally, we plot the distribution of distinct classes of the response variable to check that it is balanced before proceeding with further analysis.\n",
    "\n",
    "Source: https://elitedatascience.com/imbalanced-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    18520\n",
       "0    18520\n",
       "Name: Arrest_status, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import resample package\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Downsampling\n",
    "df_majority = incident[incident.Arrest_status==0]\n",
    "df_minority = incident[incident.Arrest_status==1]\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=18520,  # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled.Arrest_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_groups = 1\n",
    "NoArrest=df_downsampled.Arrest_status.value_counts()[0]\n",
    "Arrest=df_downsampled.Arrest_status.value_counts()[1]\n",
    " \n",
    "# create plot\n",
    "#ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.5\n",
    "opacity = 0.8\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(index, \n",
    "        NoArrest, \n",
    "        bar_width,\n",
    "        alpha=opacity,\n",
    "        color='g',\n",
    "        label='No Arrest')\n",
    " \n",
    "plt.bar(index + bar_width, \n",
    "        Arrest, \n",
    "        bar_width,\n",
    "        alpha=opacity,\n",
    "        color='r',\n",
    "        label='Arrest')\n",
    " \n",
    "plt.xlabel('Arrest Status')\n",
    "plt.ylabel('Number of Incident')\n",
    "plt.title('Dallas City Police Incident Vs. Arrest Status After Resampling')\n",
    "plt.xlim(-0.8, 2)\n",
    "plt.xticks(index + bar_width/2, (''))\n",
    "plt.legend()\n",
    " \n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Watch', 'Division', 'Day1_of_the_Week', 'Victim_Type',\n",
       "       'Victim_Race', 'Victim_Age', 'Hate_Crime', 'Gang_Related_Offense',\n",
       "       'Drug_Related', 'UCR_Offense_Name', 'X_Coordinate', 'Y_Coordinate',\n",
       "       'Number_of_offense', 'Response_time', 'Arrest_status',\n",
       "       'Call_Received_Hour', 'Res_time_category', 'IsMale',\n",
       "       'Social_crime_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incident_response_time_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    18039\n",
       "2    18039\n",
       "1    18039\n",
       "0    18039\n",
       "Name: Res_time_category, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsampling\n",
    "df_resp_cat_0 = incident_response_time_cat[incident_response_time_cat.Res_time_category==0]\n",
    "df_resp_cat_1 = incident_response_time_cat[incident_response_time_cat.Res_time_category==1]\n",
    "df_resp_cat_2 = incident_response_time_cat[incident_response_time_cat.Res_time_category==2]\n",
    "df_resp_cat_3 = incident_response_time_cat[incident_response_time_cat.Res_time_category==3]\n",
    " \n",
    "# Downsample majority class\n",
    "df_resp_downsampled_0 = resample(df_resp_cat_0, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=18039,  # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "df_resp_downsampled_1 = resample(df_resp_cat_1, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=18039,  # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "df_resp_downsampled_2 = resample(df_resp_cat_2, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=18039,  # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_resp_downsampled = pd.concat([df_resp_downsampled_0, df_resp_downsampled_1, df_resp_downsampled_2, df_resp_cat_3])\n",
    " \n",
    "# Display new class counts\n",
    "df_resp_downsampled.Res_time_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 18039\n",
      "Class 1: 18039\n",
      "Class 2: 18039\n",
      "Class 3: 18039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore response variable distribution\n",
    "plt.figure(figsize=(8,5))\n",
    "target_count = df_resp_downsampled.Res_time_category.value_counts()\n",
    "print('Class 0:', target_count[0])\n",
    "print('Class 1:', target_count[1])\n",
    "print('Class 2:', target_count[2])\n",
    "print('Class 3:', target_count[3])\n",
    "\n",
    "# print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
    "# print('Proportion1:', round(target_count[0] / target_count[2], 2), ': 1')\n",
    "# print('Proportion2:', round(target_count[0] / target_count[3], 2), ': 1')\n",
    "\n",
    "# (0-11)(Emergency), 11-31(Urgent), 31-60(Important), (60-max)(Non_Urgent)\n",
    "\n",
    "\n",
    "# data to plot\n",
    "n_groups = 1\n",
    "Emergent=df_resp_downsampled.Res_time_category.value_counts()[0]\n",
    "Urgent=df_resp_downsampled.Res_time_category.value_counts()[1]\n",
    "Important=df_resp_downsampled.Res_time_category.value_counts()[2]\n",
    "Non_Urgent=df_resp_downsampled.Res_time_category.value_counts()[3] \n",
    "\n",
    "# create plot\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.5\n",
    "opacity = 0.8\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(index, Emergent, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='g',\n",
    "                 label='Emergency')\n",
    " \n",
    "plt.bar(index + bar_width, Urgent, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 label='Urgent')\n",
    " \n",
    "plt.bar(index + bar_width+ 0.5, Important, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 label='Important')\n",
    "\n",
    "plt.bar(index + bar_width+ 1.0 , Non_Urgent, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='c',\n",
    "                 label='Non_Urgent')\n",
    "\n",
    "plt.xlabel('Response time category')\n",
    "plt.ylabel('Number of Incident')\n",
    "plt.title('Dallas City Police Incident Vs. Response time After Resampling')\n",
    "plt.xlim(-0.8, 2)\n",
    "plt.xticks(index + bar_width/2, (''))\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the down sampled dataset to the original incident data frame and continue the analysis\n",
    "incident= df_downsampled.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collinearity\n",
    "\n",
    "During Lab 1 data exploration, the team identified the attributes in the original dataset to have multicollinearity. In other words, one predictor variable in the regression model can be linearly predicted from the others with a substantial degree of accuracy.\n",
    "\n",
    "During this Mini Lab exercise, some additional collinearity was introduced because:\n",
    " * Continous Variables were converted to Categorical variables (e.g.: Response Time & Victim Age are converted to Categorical)\n",
    " * Derived Features based on (or a combination of) values of existing features (e.g.: Social Crime Score)\n",
    " * Identical features where one was a roll up of the other (e.g.: Watch & Call Received Hour)\n",
    " \n",
    "Based on the analysis of Correlation Matrix, we would be dropping one of the columns from the pair that are highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "CorrMat = incident.corr()\n",
    "\n",
    "# Highest Correlation Pairs\n",
    "corrPairs = CorrMat.unstack().sort_values(kind=\"quicksort\", ascending=False)\n",
    "\n",
    "# REMOVE DUPLICATES\n",
    "corrPairs = corrPairs[::2]\n",
    "corrPairs = corrPairs[corrPairs.index.get_level_values(0) != corrPairs.index.get_level_values(1)]\n",
    "with pd.option_context('display.max_rows',10):\n",
    "    print(corrPairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop highly correlated, insignificant and high VIF variables.\n",
    "# incident = incident.drop(['Drug_Related','Watch',Gang_Related_Offense','Hate_Crime'], axis=1)\n",
    "\n",
    "# Create correlation matrix\n",
    "CorrMat = incident.corr()\n",
    "\n",
    "# Highest Correlation Pairs\n",
    "corrPairs = CorrMat.unstack().sort_values(kind=\"quicksort\", ascending=False)\n",
    "\n",
    "# Remove Duplicates\n",
    "corrPairs = corrPairs[::2]\n",
    "corrPairs = corrPairs[corrPairs.index.get_level_values(0) != corrPairs.index.get_level_values(1)]\n",
    "with pd.option_context('display.max_rows',10):\n",
    "    print(corrPairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incident.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA DESCRIPTION TABLE HERE !!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metrics chosen for evaluation of classification models \n",
    "\n",
    "The performance of the Classification models will be measured using the following evaluation metrics:\n",
    "\n",
    " - ACCURACY: **True positive + True negative / (True positive + False positive + True negative + False negative)**. Refers to the closeness of a measured value to a standard or known value. It is the percentage of correct predictions\n",
    " \n",
    " - PRECISION: **True positive / (True positive + False positive)**. Refers to the closeness of two or more measurements to each other. It means that an algorithm returned substantially more relevant results than irrelevant ones.\n",
    " \n",
    " - RECALL: **True positive / (True positive + False negative)**. Refres to the measure of completeness or quantity. It means that an algorithm returned most of the relevant results.\n",
    " \n",
    " - F1 SCORE: Is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 score is usually more useful than accuracy, especially with an uneven class distribution\n",
    " \n",
    " - ROC & AUC: AUC is an abbrevation for Area Under the Curve. It is used in classification analysis in order to determine which of the models predicts the classes best. An example of its application are ROC curves. Here, the true positive rates are plotted against false positive rates.\n",
    "\n",
    " - NearestCentroid: The metric to use when calculating distance between instances in a feature array. If metric is a string or callable, it must be one of the options allowed by metrics.pairwise.pairwise_distances for its metric parameter. The centroids for the samples corresponding to each class is the point from which the sum of the distances (according to the metric) of all samples that belong to that particular class are minimized. If the “manhattan” metric is provided, this centroid is the median and for all other metrics, the centroid is now set to be the mean.\n",
    "\n",
    "##### Rationale for measures/metrics selected for analyzing the results of your modeling\n",
    "The metrics above provide the best measures to evaluate the models as they deliver a consistent scale on which models can be compared to each other. These types of metrics are scalar in nature where the entire model performance can be presented using a single score value. Thus, making it easier to do the comparison and analysis, although it could mask subtle details of their behaviours. Classification accuracy is the easiest classification metric to understand, but it does not tell you the underlying distribution of response values. It also does not tell you what \"types\" of errors the classifier is making. \n",
    "\n",
    "The choice of metric also depends on the business objective of focus. Identification of the False Positives or False Negatives are important so they can be reduced as appropriate to better meet objectives. Medical applications i.e. identification of cancer, daibetes or other ailments require a much higher degree of accuracy, precision and recall compared to other industry applications where it may not be so critical. \n",
    "\n",
    "If a positive class is preferable then Optimize for precision or Specificity\n",
    "If a negative class is preferred then Optimize for Sensitivity\n",
    "\n",
    "Confusion matrices provide a more complete picture of how the classifier is performing and also allows for the computation of various classification metrics which guide model selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Explain why your chosen method is appropriate or use more than one method as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stratified shufflesplit cross validation approach\n",
    "The **Stratified shufflesplit** cross validation iterator was chosen for dividing the data into training and testing data sets.  It provides train/test indices to split data into the train and test sets.\n",
    "\n",
    "- This cross-validation method is a merge of the StratifiedKFold and ShuffleSplit iterators, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.\n",
    "\n",
    "- In stratified k-fold cross-validation, the folds are selected so that the mean response value is approximately equal in all the folds. In the case of a dichotomous classification, this means that each fold contains roughly the same proportions of the two types of class labels.\n",
    "\n",
    "- The primary difference between StratifiedKFold and StratifiedShuffleSplit is that StratifiedKFold just shuffles and splits once, therefore the test sets do not overlap.  The StratifiedShuffleSplit cv method shuffles each time before splitting, and it splits n_splits times, therefore the resulting test sets can overlap.\n",
    "\n",
    "##### Why we chose this method\n",
    "Cross Validation\n",
    "We used Cross Validation to improve the classification model effectiveness. We used the below settings for cross validation.\n",
    "\n",
    "1. The data is divided into 80/20 train-test split.\n",
    "2. 10 fold cross validation\n",
    "3. Random seed with random state 0 for random test and training splits for each iteration of cross validation\n",
    "\n",
    "Parameters:\t\n",
    "y : array, [n_samples]\n",
    "\n",
    "Labels of samples.\n",
    "\n",
    "n_iter : int (default 10)\n",
    "\n",
    "Number of re-shuffling & splitting iterations.\n",
    "\n",
    "test_size : float (default 0.1), int, or None\n",
    "\n",
    "If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is automatically set to the complement of the train size.\n",
    "\n",
    "train_size : float, int, or None (default is None)\n",
    "\n",
    "If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split. If int, represents the absolute number of train samples. If None, the value is automatically set to the complement of the test size.\n",
    "\n",
    "random_state : int or RandomState\n",
    "\n",
    "Pseudo-random number generator state used for random sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification models adopted for analysis\n",
    "\n",
    "### k-NN\n",
    "In KNN classification, the output is a class membership. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.\n",
    "\n",
    "In pattern recognition, the k-nearest neighbors algorithm (k-NN) is a non-parametric method (it does not make any assumptions on the underlying data distribution) used for classification. The input consists of the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression. It is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g. distance functions).\n",
    "\n",
    "##### Limitations of k-NN\n",
    "- In high dimensions, points that may be similar may have very large distances. All points will be far away from each other and our intuition for distances in simple 2 and 3-dimensional spaces breaks down. This might feel unintuitive at first, but this general problem is called the “Curse of Dimensionality“.\n",
    "\n",
    "- Each input variable can be considered a dimension of a p-dimensional input space. For example, if you had two input variables x1 and x2, the input space would be 2-dimensional.\n",
    "\n",
    "- As the number of dimensions increases the volume of the input space increases at an exponential rate.\n",
    "\n",
    "##### Prepping for k-NN\n",
    "- Rescale Data: KNN performs much better if all of the data has the same scale. Normalizing your data to the range [0, 1] is a good idea. It may also be a good idea to standardize your data if it has a Gaussian distribution.\n",
    "\n",
    "- Address Missing Data: Missing data will mean that the distance between samples can not be calculated. These samples could be excluded or the missing values could be imputed.\n",
    "\n",
    "- Lower Dimensionality: KNN is suited for lower dimensional data. You can try it on high dimensional data (hundreds or thousands of input variables) but be aware that it may not perform as well as other techniques. KNN can benefit from feature selection that reduces the dimensionality of the input feature space.\n",
    "\n",
    "### RANDOM FORESTS\n",
    "Source: https://www.datascience.com/resources/notebooks/random-forest-intro\n",
    "\n",
    "Random forests, also known as random decision forests, are a popular ensemble method to build predictive models for both classification and regression. The ensemble methods uses multiple learning models to gain better predictive results — in the case of a random forest, the model creates an entire forest of random uncorrelated decision trees to arrive at the best possible answer.\n",
    "\n",
    "Decision trees are simple but intuitive models that utilize a top-down approach in which the root node creates binary splits until a certain criteria is met. This binary splitting of nodes provides a predicted value based on the interior nodes leading to the terminal (final) nodes. In a classification context, a decision tree will output a predicted target class for each terminal node produced.\n",
    "\n",
    "Source: www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#workings\n",
    "##### Features of Random Forests\n",
    "- Unexcelled in accuracy among current algorithms.\n",
    "- Runs efficiently on large data bases.\n",
    "- Can handle thousands of input variables without variable deletion.\n",
    "- Provides estimates of what variables are important in the classification.\n",
    "- Generates an internal unbiased estimate of the generalization error as the forest building progresses.\n",
    "- Effective method for estimating missing data and maintains accuracy when a large proportion of the data are missing.\n",
    "- Includes methods for balancing error in class population unbalanced data sets.\n",
    "- Generated forests can be saved for future use on other data.\n",
    "- Prototypes are computed that give information about the relation between the variables and the classification.\n",
    "- Computes proximities between pairs of cases that can be used in clustering, locating outliers, or (by scaling) give interesting views of the data.\n",
    "- Capabilities of the above can be extended to unlabeled data, leading to unsupervised clustering, data views and outlier detection.\n",
    "- Offers an experimental method for detecting variable interactions.\n",
    "\n",
    "##### Limitations to Decision Trees\n",
    "Decision trees tend to have high variance when they utilize different training and test sets of the same data, since they tend to overfit on training data. This leads to poor performance on unseen data. Unfortunately, this limits the usage of decision trees in predictive modeling. However, using ensemble methods, we can create models that utilize underlying decision trees as a foundation for producing powerful results.\n",
    "\n",
    "\n",
    "### SVM\n",
    "For SVM models, the interpretation of field importance is not as straight forward. Non-linear SVM models create hyperplanes in infinite dimensional space. To accomplish this the source data used in the analysis must be mapped to a higher dimensional space and as a result is very different from the original data. Because of this it is not possible to determine feature weights like we did with the logisitc regessions above.\n",
    "\n",
    "However, we can examine individual features to investigate how SVM approaches classification problems.In the case below, we are vizualizing decision boundaries of two features i.e UCR_Offense_Name and Division.\n",
    "\n",
    "- In this section, the models for classification of two task where Arrest Status and Response Time Category will be build.\n",
    "- Models per task = 3 \n",
    "- These are two predictive tasks spanning two different modes of machine learning. \n",
    "- Both prediction as a classification task.\n",
    "- The available features will be utilized for classiffication of Arrest status. \n",
    "\n",
    "- MAYBE BASE LINE AS LOGIT\n",
    "\n",
    "The cross validation will be performed for each task as mentioned........***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1\n",
    "- Arrest Status Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y Response variable dataframe\n",
    "inci_Y = incident['Arrest_status']\n",
    "\n",
    "# Features with no predictive features with respect to response variable\n",
    "inci_X = incident.drop(['Arrest_status'],axis=1)\n",
    "\n",
    "#Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "inci_X = scaler.fit_transform(inci_X)\n",
    "\n",
    "#Save as data frames\n",
    "inci_X = pd.DataFrame(inci_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Credit: https://etav.github.io/\n",
    "\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "# df2_vif = pd.DataFrame()\n",
    "# df2_vif[\"VIF Factor\"] = [vif(inci_X.values, i) for i in range(inci_X.shape[1])]\n",
    "# df2_vif[\"features\"] = inci_X.columns\n",
    "# print(\"VIF Factors before Scaling\")\n",
    "# df2_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Credit: https://etav.github.io/\n",
    "\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n",
    "# df2_vif = pd.DataFrame()\n",
    "# df2_vif[\"VIF Factor\"] = [vif(df_inci_X_scaled.values, i) for i in range(df_inci_X_scaled.shape[1])]\n",
    "# df2_vif[\"features\"] = inci_X.columns\n",
    "# print(\"VIF Factors after Scaling\")\n",
    "# df2_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOGISTIC REGRESSION: SUMMARY TABLE WITHOUT SCALING- FEATURE SIGNIFICANCE, CROSS VALIDATION OF FULL MODEL\n",
    "# from sklearn import metrics as mt\n",
    "# import statsmodels.api as sm\n",
    "# logit_model = sm.Logit(inci_Y, inci_X)\n",
    "# result = logit_model.fit()\n",
    "# print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###### Cross Validation\n",
    "\n",
    "For the below model execution, we use Cross Validation to improve the model classification. We use the below settings for cross validation.\n",
    "\n",
    "    1. The data is divided into 80/20 train-test split. ### why?\n",
    "    2. 10 fold cross validation\n",
    "    3. Random seed with random state 0 for random test and training splits for each iteration of cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Create Cross Validation object with 10 fold and 80/20 train-test split\n",
    "cv = ShuffleSplit(n_splits = 10, test_size=0.20, random_state=0)\n",
    "\n",
    "\n",
    "inci_X = inci_X.as_matrix().astype(np.float)\n",
    "inci_Y = inci_Y.as_matrix().astype(np.float)\n",
    "\n",
    "for trainidx, testidx in cv.split(inci_X,inci_Y):\n",
    "    X_train, X_test = inci_X[trainidx], inci_X[testidx]    \n",
    "    y_train, y_test = inci_Y[trainidx], inci_Y[testidx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1.1\n",
    "###### KNN Classification \n",
    "\n",
    "- Parameter Optimization\n",
    "\n",
    "K-Nearest Neighbor (KNN) classification is a valid option for this dataset since the dataset has been preprocessed and has no missing values. Parameter selections are critical to the performance of KNN classifiers; therefore, substantial time and effort was put forth to fully investigate the optimal parameters.\n",
    "\n",
    "##### Parameter Settings\n",
    "n_neighbors=K (k=20)\n",
    "\n",
    "weights='uniform'\n",
    "\n",
    "metric='euclidean'\n",
    "\n",
    "##### Visualizations\n",
    "Error Rate vs. K Value\n",
    "\n",
    "**Writeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, precision_score, precision_recall_fscore_support\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "error_rate = []\n",
    "acc_score  = []\n",
    "pres_score = []\n",
    "\n",
    "for K in np.arange(1, 20, 1):\n",
    "    print(\"Iteration:: \",K)\n",
    "    knn = KNeighborsClassifier(n_neighbors=K, weights='uniform', metric='euclidean')\n",
    "    knn.fit(X_train,y_train)\n",
    "    yhat = knn.predict(X_test)\n",
    "    \n",
    "    error_rate.append(np.mean(yhat != y_test))\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    pres = precision_score(y_test, yhat)\n",
    "    acc_score.append(acc)\n",
    "    pres_score.append(pres)\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test, yhat))\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test, yhat))\n",
    "    print('Accuracy of classifier with %d neighbors is: %.2f'%(K,acc))\n",
    "    print('Precision Score of classifier with %d neighbors is: %.2f'%(K,pres))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(np.arange(1, 20, 1),error_rate,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\n",
    "plt.plot(np.arange(1, 20, 1),acc_score,color='red', linestyle='dashed', marker='o', markerfacecolor='blue', markersize=10)\n",
    "plt.plot(np.arange(1, 20, 1),pres_score,color='green', linestyle='dashed', marker='o', markerfacecolor='black', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "\n",
    "def per_class_accuracy(ytrue,yhat):\n",
    "    conf = mt.confusion_matrix(ytrue,yhat)\n",
    "    norm_conf = conf.astype('float') / conf.sum(axis=1)[:, np.newaxis]\n",
    "    return np.diag(norm_conf)\n",
    "\n",
    "def plot_class_acc(ytrue,yhat, title=''):\n",
    "    acc_list = per_class_accuracy(ytrue,yhat)\n",
    "    plt.bar(range(len(acc_list)), acc_list)\n",
    "    plt.xlabel('Class value')\n",
    "    plt.ylabel('Accuracy within class')\n",
    "    plt.title(title+\", Total Acc=%.1f\"%(100*mt.accuracy_score(ytrue,yhat)))\n",
    "    plt.grid()\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()\n",
    "    \n",
    "plot_class_acc(y_test,yhat,title=\"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest Classifier \n",
    "- Parameter Optimization\n",
    "\n",
    "\n",
    "##### Parameter Settings\n",
    "max_depth=50\n",
    "n_estimators=150\n",
    "n_jobs=-1\n",
    "oob_score=True\n",
    "\n",
    "##### Visualizations\n",
    "\n",
    "\n",
    "**Writeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=50, n_estimators=150, n_jobs=-1, oob_score=True)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "yhat = clf.predict(X_test)\n",
    "    \n",
    "total_accuracy = mt.accuracy_score(y_test, yhat)\n",
    "total_precision = precision_score(y_test, yhat)\n",
    "print ('Accuracy', total_accuracy)\n",
    "print ('Precision', total_precision)\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, yhat))\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "plot_class_acc(y_test,yhat,title=\"Random Forest, Raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearestCentroid\n",
    "- Parameter Optimization\n",
    "\n",
    "\n",
    "##### Parameter Settings\n",
    "NearestCentroid\n",
    "'l1', \n",
    "'l2', \n",
    "'cosine', \n",
    "'euclidean'\n",
    "\n",
    "##### Visualizations\n",
    "\n",
    "\n",
    "**Writeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "for d in ['l1', 'l2', 'cosine', 'euclidean']:\n",
    "    clf = NearestCentroid(metric=d)\n",
    "    clf.fit(X_train, y_train)\n",
    "    yhat = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    pres = precision_score(y_test, yhat)\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test, yhat))\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test, yhat))\n",
    "    print('Accuracy of classifier with %s metric is: %.2f'%(d,acc))\n",
    "    print('Precision Score of classifier with %s metric is: %.2f'%(d,pres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2\n",
    "- Using the Response Time Category variable for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y Response variable dataframe\n",
    "inci_res_Y = incident['Res_time_category']\n",
    "\n",
    "# Features with no predictive features with respect to response variable\n",
    "inci_res_X = incident.drop(['Res_time_category', 'Response_time'],axis=1)  # Added Response_time to drop as it was causing accuracy to be 1\n",
    "\n",
    "#Scale data                                                                            # Try removing ARREST STATUS for this too\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "inci_res_X = scaler.fit_transform(inci_res_X)\n",
    "\n",
    "#Save as data frames\n",
    "inci_res_X = pd.DataFrame(inci_res_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "inci_res_X = inci_res_X#.as_matrix().astype(np.float)\n",
    "inci_res_Y = inci_res_Y#.as_matrix().astype(np.float)\n",
    "\n",
    "for trainidx, testidx in cv.split(inci_res_X,inci_res_Y):\n",
    "    X_train_R, X_test_R = inci_res_X[trainidx], inci_res_X[testidx]    \n",
    "    y_train_R, y_test_R = inci_res_Y[trainidx], inci_res_Y[testidx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2.1\n",
    "- KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, precision_score, precision_recall_fscore_support\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "error_rate = []\n",
    "acc_score = []\n",
    "pres_score = []\n",
    "\n",
    "for K in np.arange(1, 20, 1):\n",
    "    print(\"Iteration:: \",K)\n",
    "    knn = KNeighborsClassifier(n_neighbors=K, weights='uniform', metric='euclidean')\n",
    "    knn.fit(X_train_R,y_train_R)\n",
    "    yhat= knn.predict(X_test_R)\n",
    "    \n",
    "    error_rate.append(np.mean(yhat != y_test))\n",
    "    acc = accuracy_score(y_test_R, yhat)\n",
    "    pres = precision_score(y_test_R, yhat, average='weighted')\n",
    "    acc_score.append(acc)\n",
    "    pres_score.append(pres)\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test_R, yhat))\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test_R, yhat))\n",
    "    print('Accuracy of classifier with %d neighbors is: %.2f'%(K,acc))\n",
    "    print('Precision Score of classifier with %d neighbors is: %.2f'%(K,pres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2.2\n",
    "- Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=20, n_estimators=150, n_jobs=-1, oob_score=True, class_weight=\"balanced\")\n",
    "\n",
    "clf.fit(X_train_R,y_train_R)\n",
    "yhat = clf.predict(X_test_R)\n",
    "    \n",
    "total_accuracy = mt.accuracy_score(y_test_R, yhat)\n",
    "total_precision = precision_score(y_test_R, yhat, average='weighted')\n",
    "print ('Accuracy', total_accuracy)\n",
    "print ('Precision', total_precision)\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test_R, yhat))\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test_R, yhat))\n",
    "plot_class_acc(y_test_R,yhat,title=\"Random Forest, Raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "clf_pipe = Pipeline(\n",
    "    [('PCA',PCA(n_components=11, svd_solver='randomized')),\n",
    "     ('CLF',RandomForestClassifier(max_depth=50, n_estimators=150, n_jobs=-1))]\n",
    ")\n",
    "\n",
    "total_accuracy = mt.accuracy_score(y_test_R, yhat)\n",
    "total_precision = precision_score(y_test_R, yhat, average='weighted')\n",
    "print ('Pipeline Accuracy', total_accuracy)\n",
    "print ('Precision', total_precision)\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test_R, yhat))\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test_R, yhat))\n",
    "plot_class_acc(y_test_R,yhat,title=\"Random Forest, Raw\")  # PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3\n",
    "- NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "for d in ['l1', 'l2', 'cosine', 'euclidean']:\n",
    "    clf = NearestCentroid(metric=d)\n",
    "    clf.fit(X_train_R, y_train_R)\n",
    "    yhat = clf.predict(X_test_R)\n",
    "    acc = accuracy_score(y_test_R, yhat)\n",
    "    pres = precision_score(y_test_R, yhat, average='weighted')\n",
    "    print('Classification Report')\n",
    "    print(classification_report(y_test_R, yhat))\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test_R, yhat))\n",
    "    print('Accuracy of classifier with %s metric is: %.2f'%(d,acc))\n",
    "    print('Precision Score of classifier with %s metric is: %.2f'%(d,pres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 4\n",
    "\n",
    "- Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Credit To: https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "# Compare Algorithms\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# models = []\n",
    "# models.append(('LR', LogisticRegression()))\n",
    "# models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "# models.append(('KNN', KNeighborsClassifier()))\n",
    "# models.append(('CART', DecisionTreeClassifier()))\n",
    "# models.append(('NB', GaussianNB()))\n",
    "# models.append(('SVM', SVC()))\n",
    "\n",
    "# ***********MODELS FUNCTION*************\n",
    "# evaluate each model in turn\n",
    "def Results_analysis(fmodels, fscoring, fX, fy):\n",
    "    results = []\n",
    "    names = []\n",
    "    #scoring = 'accuracy'\n",
    "    for name, model in fmodels:\n",
    "        if (fscoring == 'accuracy'):\n",
    "            skf = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "        else:\n",
    "            skf = 10\n",
    "        cv_results = model_selection.cross_val_score(model, fX, fy, cv=skf, scoring=fscoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Algorithm Comparison')\n",
    "    sns.boxplot(x=names, y=results, palette=\"Set1\")\n",
    "    plt.show()\n",
    "    \n",
    "    return [names, results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrest Status (models in TASK 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Credit To: https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "seed = 7\n",
    "# prepare models\n",
    "class_models = []\n",
    "class_models.append(('LDA', LinearDiscriminantAnalysis(n_components=1, priors=None, solver='lsqr')))\n",
    "class_models.append(('KNN', KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski', \n",
    "                                           metric_params=None, n_jobs=-1, n_neighbors=13, p=2,\n",
    "                                           weights='uniform')))\n",
    "class_models.append(('RF', RandomForestClassifier(n_estimators=600, max_depth=None, min_samples_split=2, random_state=0,  n_jobs=-1)))\n",
    "class_models.append(('RFET', ExtraTreesClassifier(n_estimators=600, max_depth=None, min_samples_split=2, random_state=0,  n_jobs=-1)))\n",
    "\n",
    "class_models.append(('NearestCentroid', NearestCentroid(metric='cosine')))\n",
    "class_models.append(('NB', GaussianNB()))\n",
    "\n",
    "\n",
    "\n",
    "classModelResults = Results_analysis(class_models, 'accuracy', X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Time Category (models in TASK 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Credit To: https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "seed = 7\n",
    "# prepare models\n",
    "class_models_R = []\n",
    "\n",
    "# class_models_R.append(('LDA', LinearDiscriminantAnalysis(n_components=1, priors=None, solver='lsqr')))\n",
    "class_models_R.append(('KNN', KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski', \n",
    "                                           metric_params=None, n_jobs=-1, n_neighbors=13, p=2,\n",
    "                                           weights='uniform')))\n",
    "class_models_R.append(('RF', RandomForestClassifier(n_estimators=600, max_depth=None, min_samples_split=2, random_state=0,  n_jobs=-1)))\n",
    "class_models_R.append(('RFET', ExtraTreesClassifier(n_estimators=600, max_depth=None, min_samples_split=2, random_state=0,  n_jobs=-1)))\n",
    "\n",
    "class_models_R.append(('NearestCentroid', NearestCentroid(metric='l1')))\n",
    "\n",
    "class_models_R.append(('RF+PCA',Pipeline([('PCA',PCA(n_components=11, svd_solver='randomized')),\n",
    "                                    ('CLF',RandomForestClassifier(max_depth=50, n_estimators=150, n_jobs=-1))])))\n",
    "\n",
    "\n",
    "classModelResults_R = Results_analysis(class_models_R, 'accuracy', X_test_R, y_test_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 5 \n",
    "\n",
    "- Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit: https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "# credit: https://stackoverflow.com/questions/5389507/iterating-over-every-two-elements-in-a-list\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "\n",
    "# Iterate Pairwise through models and calculate CI\n",
    "def modelCiComp(modelResults):\n",
    "    for i in range(len(classModelResults[0])):\n",
    "        for j in range(i+1, len(classModelResults[1])):\n",
    "            m1Acc = classModelResults[1][i]\n",
    "            m2Acc = classModelResults[1][j]\n",
    "            d = m1Acc - m2Acc\n",
    "            dBar = np.mean(d)\n",
    "            v = np.var(d)\n",
    "            ci = (1/sqrt(len(m1Acc)))*stats.t.ppf(q = .975, df = len(m1Acc) - 1)*sqrt(v)\n",
    "            ci = \"[\" + str(round(dBar - ci, 5)) + \", \" + str(round(dBar + ci, 5)) + \"]\"\n",
    "            print(\"95% CI for\", classModelResults[0][i], \"vs\", classModelResults[0][j], \"=\", ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrest Status models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCiComp(classModelResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response time category models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCiComp(classModelResults_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 6 \n",
    "\n",
    "- Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrest status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN: 0.705720 (0.012338)\n",
    "\n",
    "# now lets get access to the different properties of our RF\n",
    "clf = RandomForestClassifier(max_depth=20, n_estimators=150, n_jobs=-1, oob_score=True, class_weight=\"balanced\")\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "    \n",
    "print (clf)\n",
    "\n",
    "plt.barh(range(len(clf.feature_importances_)), clf.feature_importances_)\n",
    "plt.show()\n",
    "\n",
    "print ('Generalization score estimate from training data', clf.oob_score_)\n",
    "\n",
    "\n",
    "# oob_SCORE - Very close to accuracy, represents data which are not just a guess and are not placed on the main data for ..\n",
    "# ..do not use it as a replacement to cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response time cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN: 0.705720 (0.012338)\n",
    "\n",
    "# now lets get access to the different properties of our RF\n",
    "clf = RandomForestClassifier(max_depth=20, n_estimators=150, n_jobs=-1, oob_score=True, class_weight=\"balanced\")\n",
    "\n",
    "clf.fit(X_train_R, y_train_R)\n",
    "    \n",
    "print (clf)\n",
    "\n",
    "plt.barh(range(len(clf.feature_importances_)), clf.feature_importances_)\n",
    "plt.show()\n",
    "\n",
    "print ('Generalization score estimate from training data', clf.oob_score_)\n",
    "\n",
    "\n",
    "# oob_SCORE - Very close to accuracy, represents data which are not just a guess and are not placed on the main data for ..\n",
    "# ..do not use it as a replacement to cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier()\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(X_train_R, y_train_R)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(X_train_R.shape[1]), importances[indices],\n",
    "       color=\"r\", xerr=std[indices], align=\"center\")\n",
    "\n",
    "# If you want to define your own labels,\n",
    "# change indices to a list of labels on the following line.\n",
    "plt.yticks(range(X_train_R.shape[1]), indices)\n",
    "plt.ylim([-1, X_train_R.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# def plotCoef(coef, names, t):\n",
    "#     imp = coef\n",
    "#     imp,names = zip(*sorted(zip(imp,names), key=lambda x: abs(x[0])))\n",
    "#     plt.figure(figsize=(9,12))\n",
    "#     barlist = plt.barh(range(len(names)), imp, align='center')\n",
    "#     for x in np.nditer(np.where(np.asarray(list(imp)) < 0)):\n",
    "#         barlist[x].set_color('r')\n",
    "#     plt.yticks(range(len(names)), names)\n",
    "#     plt.title(t)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotCoef(regGridSearch.best_estimator_.coef_[0], inci_X.columns.values, \"Manual Logistic Features\")\n",
    "# list(sorted(zip(regGridSearch.best_estimator_.coef_.ravel(), inci_X.columns.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "- How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work \n",
    "\n",
    "- You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from sklearn.decomposition import PCA \n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # setup pipeline to take PCA, then fit a KNN classifier\n",
    "# clf_pipe = Pipeline(\n",
    "#     [('PCA_Eric',PCA(n_components=11,svd_solver='randomized')),\n",
    "#      ('CLF_Eric',KNeighborsClassifier(n_neighbors=1))]\n",
    "# )\n",
    "\n",
    "# # now iterate through and get predictions, saved to the correct row in yhat\n",
    "# for train, test in cv.split(X,y):\n",
    "#     clf_pipe.fit(X[train],y[train])\n",
    "#     yhat[test] = clf_pipe.predict(X[test])\n",
    "\n",
    "# total_accuracy = mt.accuracy_score(y, yhat)\n",
    "# print ('KNN, pipeline accuracy', total_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def per_class_accuracy(ytrue,yhat):\n",
    "#     conf = mt.confusion_matrix(ytrue,yhat)\n",
    "#     norm_conf = conf.astype('float') / conf.sum(axis=1)[:, np.newaxis]\n",
    "#     return np.diag(norm_conf)\n",
    "\n",
    "# def plot_class_acc(ytrue,yhat, title=''):\n",
    "#     acc_list = per_class_accuracy(ytrue,yhat)\n",
    "#     plt.bar(range(len(acc_list)), acc_list)\n",
    "#     plt.xlabel('Class value (one per face)')\n",
    "#     plt.ylabel('Accuracy within class')\n",
    "#     plt.title(title+\", Total Acc=%.1f\"%(100*mt.accuracy_score(ytrue,yhat)))\n",
    "#     plt.grid()\n",
    "#     plt.ylim([0,1])\n",
    "#     plt.show()\n",
    "    \n",
    "# plot_class_acc(y,yhat,title=\"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# clf_pipe = Pipeline(\n",
    "#     [('PCA',PCA(n_components=11, svd_solver='randomized')),\n",
    "#      ('CLF',RandomForestClassifier(max_depth=50, n_estimators=150, n_jobs=-1))]\n",
    "# )\n",
    "\n",
    "# # now iterate through and get predictions, saved to the correct row in yhat\n",
    "# for train, test in cv.split(X,y):\n",
    "#     clf_pipe.fit(X[train],y[train])\n",
    "#     yhat[test] = clf_pipe.predict(X[test])\n",
    "    \n",
    "# total_accuracy = mt.accuracy_score(y, yhat)\n",
    "# print ('Pipeline accuracy', total_accuracy)\n",
    "# plot_class_acc(y,yhat,title=\"Random Forest + PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# clf = RandomForestClassifier(max_depth=50, n_estimators=150, n_jobs=-1, oob_score=True)\n",
    "\n",
    "# # now iterate through and get predictions, saved to the correct row in yhat\n",
    "# for train, test in cv.split(X,y):\n",
    "#     clf.fit(X[train],y[train])\n",
    "#     yhat[test] = clf.predict(X[test])\n",
    "    \n",
    "# total_accuracy = mt.accuracy_score(y, yhat)\n",
    "# print ('Accuracy', total_accuracy)\n",
    "# plot_class_acc(y,yhat,title=\"Random Forest, Raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall importance of each feature, magnitude of feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREE ENSEMBLE METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "num_estimators = 50\n",
    "# lets train some trees\n",
    "clf_array = [\n",
    "    ('Stump',              DecisionTreeClassifier(max_depth=1, min_samples_leaf=1)),\n",
    "    ('Tree',               DecisionTreeClassifier()),\n",
    "    ('Random Trees',       RandomForestClassifier(max_depth=50, n_estimators=num_estimators)),\n",
    "    ('Extra Random Trees', ExtraTreesClassifier(n_estimators=num_estimators,min_samples_split=2)),\n",
    "    ('Boosted Tree',       GradientBoostingClassifier(n_estimators=num_estimators)), #takes a long time\n",
    "    ]\n",
    "\n",
    "for clf in clf_array:\n",
    "    acc = cross_val_score(clf[1],X,y)\n",
    "    print (clf[0], acc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.svm import SVC\n",
    "# # from sklearn.linear_model import LogisticRegression\n",
    "# # from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# # setup pipeline to take PCA, then fit a different classifier\n",
    "# clf_pipe = Pipeline(\n",
    "#     [('PCA',PCA(n_components=11,svd_solver='randomized')),\n",
    "#      ('CLF',GaussianNB())]\n",
    "# )\n",
    "\n",
    "# # now iterate through and get predictions, saved to the correct row in yhat\n",
    "# for train, test in cv.split(X,y):\n",
    "#     clf_pipe.fit(X[train],y[train])\n",
    "#     yhat[test] = clf_pipe.predict(X[test])\n",
    "\n",
    "# total_accuracy = mt.accuracy_score(y, yhat)\n",
    "# print ('Pipeline accuracy', total_accuracy)\n",
    "# plot_class_acc(y,yhat,title=\"Naive Bayes + PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# # setup pipeline to take PCA, then fit a different classifier\n",
    "# clf_pipe = Pipeline(\n",
    "#     [('PCA',PCA(n_components=11,svd_solver='randomized')),\n",
    "#      ('CLF',GaussianNB())]\n",
    "# )\n",
    "\n",
    "# yhat_score = np.zeros((y.shape[0],len(X)))\n",
    "\n",
    "# # now iterate through and get predictions, saved to the correct row in yhat\n",
    "# for train, test in cv.split(X,y):\n",
    "#     clf_pipe.fit(X[train],y[train])\n",
    "#     yhat[test] = clf_pipe.predict(X[test])\n",
    "#     yhat_score[test] = clf_pipe.predict_proba(X[test])\n",
    "\n",
    "# total_accuracy = mt.accuracy_score(y, yhat)\n",
    "# print ('Pipeline accuracy', total_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.set_palette(\"dark\")\n",
    "# # code manipulated from http://scikit-learn.org/stable/auto_examples/plot_roc.html\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# # Compute ROC curve for a subset of interesting classes\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "# for i in np.unique(y):\n",
    "#     fpr[i], tpr[i], _ = mt.roc_curve(y, yhat_score[:, i], pos_label=i)\n",
    "#     roc_auc[i] = mt.auc(fpr[i], tpr[i])\n",
    "\n",
    "# for i in np.random.permutation(60)[0:6]:\n",
    "#     plt.plot(fpr[i], tpr[i], label='class {0} with {1} instances (area = {2:0.2f})'\n",
    "#                                    ''.format(i, sum(y==i), roc_auc[i]))\n",
    "\n",
    "# plt.legend(loc=\"lower right\")  \n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combined ROC over all classes\n",
    "# one_hot_class_encoding = label_binarize(y,np.unique(y))\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = mt.roc_curve(one_hot_class_encoding.ravel(), yhat_score.ravel())\n",
    "# roc_auc[\"micro\"] = mt.auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# plt.figure(figsize=(12,4))\n",
    "# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "#          label='micro-average ROC curve (area = {0:0.2f})'\n",
    "#                ''.format(roc_auc[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
